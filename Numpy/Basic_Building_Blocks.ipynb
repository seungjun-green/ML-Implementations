{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JnK2BF88fJ2f"
      },
      "outputs": [],
      "source": [
        "!pip install -q colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z_36eIZLShTd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from colorama import init, Fore\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kHB5k3p1TKIf"
      },
      "outputs": [],
      "source": [
        "class HelperFunction:\n",
        "  @staticmethod\n",
        "  def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwi0Wdqmf3vq"
      },
      "source": [
        "### Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zE_Lasd9TSIA"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "  def __init__(self, in_features, out_features, bias=True):\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.weight = np.random.rand(out_features, in_features)\n",
        "    self.bias = np.random.rand(out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    input: (N, in_features)\n",
        "    output: (N, out_features)\n",
        "    '''\n",
        "    x = np.dot(x, self.weight.T) + self.bias\n",
        "    x = HelperFunction.relu(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7ssXALgHTQ",
        "outputId": "f903fe55-b0e3-46f0-be8d-438f02cf9087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_linear_layers(idx, in_features, out_features, batch_size):\n",
        "    my_model = Linear(in_features=in_features, out_features=out_features)\n",
        "    torch_model = nn.Linear(in_features=in_features, out_features=out_features)\n",
        "\n",
        "    x_np = np.random.randn(batch_size, in_features).astype(np.float32)\n",
        "    x_torch = torch.tensor(x_np, dtype=torch.float32)\n",
        "\n",
        "    my_output = my_model.forward(x_np)\n",
        "    torch_output = torch_model(x_torch).detach().numpy()\n",
        "\n",
        "    assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {my_output.shape}\"\n",
        "    print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_linear():\n",
        "    test_cases = [\n",
        "        {'in_features': 10, 'out_features': 5, 'batch_size': 32},\n",
        "        {'in_features': 20, 'out_features': 10, 'batch_size': 64},\n",
        "        {'in_features': 50, 'out_features': 25, 'batch_size': 16}\n",
        "    ]\n",
        "\n",
        "    for idx, params in enumerate(test_cases):\n",
        "      compare_linear_layers(idx, **params)\n",
        "\n",
        "    print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_linear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqqQuRwRT9HB"
      },
      "source": [
        "### NeuralNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r_tYDHH8T_O7"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    self.layer1 = Linear(in_features=8, out_features=32)\n",
        "    self.layer2 = Linear(in_features=32, out_features=64)\n",
        "    self.layer3 = Linear(in_features=64, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1.forward(x)\n",
        "    x = self.layer2.forward(x)\n",
        "    x = self.layer3.forward(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln7hztDJUhpr",
        "outputId": "45e8bfdb-1b9b-47fd-fc4d-cb9cad11f1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output shape: (1000, 1)\n"
          ]
        }
      ],
      "source": [
        "sample_nn = NeuralNetwork()\n",
        "sample_input = np.random.rand(1000, 8)\n",
        "output = sample_nn.forward(sample_input)\n",
        "print(f\"output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKSPldjHBsUk"
      },
      "source": [
        "### Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omtgk-kiJsO8"
      },
      "source": [
        "Originally we do convlution liek tihs\n",
        "for each image (C_in, H, W) we do convolution with a filter(C_in, K, K) then this create (new_H, new_W)\n",
        "\n",
        "we do this with C_out number of filters so we get (C_out, new_H, new_W)\n",
        "\n",
        "so here idea is doing this as\n",
        "(C_in, H, W) and (C_out, C_in, K, K).\n",
        " and make a original image to be shape of (C_out, C_in, H, W)\n",
        "\n",
        "\n",
        " BUt let's fo futher then do this\n",
        " (N, C_out, C_in, H, W) and (N, C_out, C_in, K, K)\n",
        " (N, C_out, C_in, H, W) * (N, C_out, C_in, K, K) => (N, C_out, C_in, K, K)\n",
        "\n",
        " then find the max value in (C_in, K, K) then we get (N, C_out, 1, 1)\n",
        "\n",
        " do this for all 2d dimension(new_HX newW) then we get (N, C_out, new_H, new_H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VPbPes3IBt0Y"
      },
      "outputs": [],
      "source": [
        "class Conv2d:\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.filters = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) # (out_channels, in_channels, K, K)\n",
        "    self.bais = np.random.randn(out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    input: (N, C_in, H, W)\n",
        "    output: (N, C_out, new_h, new_W)\n",
        "    '''\n",
        "    N, C, H, W = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
        "\n",
        "    if self.padding > 0:\n",
        "      x = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "\n",
        "    new_H = int((H + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "    new_W = int((W + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "\n",
        "    filters = np.repeat(self.filters[np.newaxis, :, :, :, :], N, axis=0)\n",
        "    result = np.zeros((N, self.out_channels, new_H, new_W))\n",
        "    for h in range(0, new_H, self.stride):\n",
        "      for w in range(0, new_W, self.stride):\n",
        "        curr = x[:, :, h:h+self.kernel_size, w:w+self.kernel_size]  # (N, C_in, K, K)\n",
        "        modified_curr = np.repeat(curr[:, np.newaxis, :, :, :], self.out_channels, axis=1) # (N, C_out, C_in, K, K)\n",
        "        curr_res = modified_curr * filters # (N, C_out, C_in, K, K)\n",
        "        curr_conv = np.max(curr_res, axis=(2, 3, 4), keepdims=False) + self.bais # (N, C_out)\n",
        "        result[:, :, h:h+1, w:w+1] = np.expand_dims(np.expand_dims(curr_conv, axis=-1), axis=-1) # (N, C_out, 1, 1)\n",
        "\n",
        "    result = HelperFunction.relu(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDw6FJUNt-Dv",
        "outputId": "376302d2-faf3-442a-d98d-8005d017d27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_conv_layers(idx, in_channels, out_channels, kernel_size, stride, padding, input_shape):\n",
        "  my_model = Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "  torch_model = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "  x_np = np.random.randn(*input_shape).astype(np.float32)\n",
        "  x_torch = torch.tensor(x_np)\n",
        "  my_output = my_model.forward(x_np)\n",
        "  torch_output = torch_model(x_torch).detach().numpy()\n",
        "  assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {torch_output.shape}\"\n",
        "  print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_conv():\n",
        "  test_cases = [\n",
        "      {'in_channels': 3, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'input_shape': (32, 3, 64, 64)},\n",
        "      {'in_channels': 3, 'out_channels': 8, 'kernel_size': 5, 'stride': 2, 'padding': 2, 'input_shape': (16, 3, 32, 32)},\n",
        "      {'in_channels': 1, 'out_channels': 10, 'kernel_size': 3, 'stride': 1, 'padding': 0, 'input_shape': (10, 1, 28, 28)}\n",
        "    ]\n",
        "\n",
        "  for idx, params in enumerate(test_cases):\n",
        "    compare_conv_layers(idx, **params)\n",
        "\n",
        "  print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_conv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnBHIzmyU7Nb"
      },
      "source": [
        "### Transpose Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TD3gA27-U_bP"
      },
      "outputs": [],
      "source": [
        "class ConvTranspose2d:\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.filters = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) # (out_channels, in_channels, K, K)\n",
        "    self.bais = np.random.randn(out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    input: (N, C_in, H, W)\n",
        "    output: (N, C_out, new_h, new_W)\n",
        "    '''\n",
        "    N, C, H, W = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
        "\n",
        "    if self.padding > 0:\n",
        "      x = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "\n",
        "    new_H = int(self.stride*(H - 1) - 2*self.padding + self.kernel_size)\n",
        "    new_W = int(self.stride*(W - 1) - 2*self.padding + self.kernel_size)\n",
        "\n",
        "    filters = np.repeat(self.filters[np.newaxis, :, :, :, :], N, axis=0)\n",
        "    result = np.zeros((N, self.out_channels, new_H, new_W))\n",
        "    for h in range(0, H, self.stride):\n",
        "      for w in range(0, W, self.stride):\n",
        "        curr = x[:, :, h:h+1, w:w+1]  # (N, C_in, 1, 1)\n",
        "        curr = np.repeat(np.repeat(curr, self.kernel_size, axis=2), self.kernel_size, axis=3) # (N, C_in, K, K)\n",
        "        modified_curr = np.repeat(curr[:, np.newaxis, :, :, :], self.out_channels, axis=1) # (N, C_out, C_in, K, K)\n",
        "        curr_res = modified_curr * filters # (N, C_out, C_in, K, K)\n",
        "        curr_trans = np.sum(curr_res, axis=2)\n",
        "        result[:, :, h:h+self.kernel_size, w:w+self.kernel_size] += curr_trans\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-chWPxVp2kHT",
        "outputId": "18e8a1a6-3c26-41b5-e3f9-f7f3e60b73ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_convTrans_layers(idx, in_channels, out_channels, kernel_size, stride, padding, input_shape):\n",
        "  my_model = ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "  torch_model = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "  x_np = np.random.randn(*input_shape).astype(np.float32)\n",
        "  x_torch = torch.tensor(x_np)\n",
        "  my_output = my_model.forward(x_np)\n",
        "  torch_output = torch_model(x_torch).detach().numpy()\n",
        "  assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {torch_output.shape}\"\n",
        "  print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_convTrans():\n",
        "  test_cases = [\n",
        "      {'in_channels': 3, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'input_shape': (32, 3, 64, 64)},\n",
        "      {'in_channels': 3, 'out_channels': 8, 'kernel_size': 5, 'stride': 2, 'padding': 2, 'input_shape': (16, 3, 32, 32)},\n",
        "      {'in_channels': 1, 'out_channels': 10, 'kernel_size': 3, 'stride': 1, 'padding': 0, 'input_shape': (10, 1, 28, 28)}\n",
        "    ]\n",
        "\n",
        "  for idx, params in enumerate(test_cases):\n",
        "    compare_convTrans_layers(idx, **params)\n",
        "\n",
        "  print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_convTrans()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BV6ZFnOmeNv"
      },
      "source": [
        "### Pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF5ph8CXBff0"
      },
      "source": [
        "predifne the output, iterating the 3d dimension work all the ways [:, :, h, w]\n",
        "\n",
        "\n",
        "Iterating the 2D dimension(H X W):\n",
        "  get the max of current window(N, C, K, K) => (N ,C , 1, 1)\n",
        "  insert (N, C, 1, 1) to the position of result/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OYO8wY5YmfUM"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d:\n",
        "  def __init__(self, kernel_size, stride, padding):\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "\n",
        "    assert self.padding < self.kernel_size / 2, \"Padding must be smaller than half of the kernel size\"\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    input:\n",
        "      x: (N, C, H, W)\n",
        "    output:\n",
        "      result: (N, C, new_H, new_W)\n",
        "    '''\n",
        "    N, C, H, W = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
        "\n",
        "    # add padding to input x if self.padding is bigger than 0\n",
        "    # (N, C, H, W) -> (N, C, H+2*self.padding, W+2*self.padding)\n",
        "    if self.padding > 0:\n",
        "      x = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "\n",
        "    new_H = int((H + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "    new_W = int((W + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "\n",
        "    output = np.zeros((N, C, new_H, new_W))\n",
        "\n",
        "    for h in range(0, new_H, self.stride):\n",
        "      for w in range(0, new_W, self.stride):\n",
        "        # (N C, K, K) -> (N C, 1, 1) and then put this into right positioj\n",
        "        curr_selection = x[:, :, h:h+self.kernel_size, w:w+self.kernel_size]\n",
        "        pooled = np.max(curr_selection, axis=(2,3), keepdims=True)\n",
        "        output[:, :, h:h+1, w:w+1] = pooled\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FPWoVDNdBYe"
      },
      "source": [
        "Check if it is working well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcg2c0FBdEeR",
        "outputId": "97e53c6f-fe65-428c-e35f-c9da104e452f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_pooling_layers(idx, kernel_size, stride, padding, input_shape):\n",
        "  my_model = MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "  torch_model = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "  x_np = np.random.randn(*input_shape).astype(np.float32)\n",
        "  x_torch = torch.tensor(x_np)\n",
        "  my_output = my_model.forward(x_np)\n",
        "  torch_output = torch_model(x_torch).detach().numpy()\n",
        "  assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {torch_output.shape}\"\n",
        "  print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_pool():\n",
        "  test_cases = [\n",
        "      {'kernel_size': 12, 'stride': 2, 'padding': 5, 'input_shape': (32, 3, 64, 64)},\n",
        "      {'kernel_size': 8, 'stride': 3, 'padding': 3, 'input_shape': (16, 1, 32, 32)},\n",
        "      {'kernel_size': 5, 'stride': 1, 'padding': 2, 'input_shape': (10, 5, 28, 28)}\n",
        "  ]\n",
        "\n",
        "  for idx, params in enumerate(test_cases):\n",
        "    compare_pooling_layers(idx, **params)\n",
        "\n",
        "  print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_pool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPdknI2Tf6nf"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nyqtiCynTaXv"
      },
      "outputs": [],
      "source": [
        "class Embedding:\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    self.E = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Input:\n",
        "      x: (N, L)\n",
        "    Output:\n",
        "      result: (N, L, embdding_dim)\n",
        "    '''\n",
        "    res = []\n",
        "    for i in range(x.shape[0]):\n",
        "        curr = self.E[x[i], :] # (L, embedding_dim)\n",
        "        res.append(curr)\n",
        "    result = np.stack(res, axis=0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhQQ4lgO2_5H",
        "outputId": "d7a79747-dc1c-4909-88ee-88ad253414f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_embedding_layers(idx, vocab_size, embedding_dim, input_shape):\n",
        "    my_model = Embedding(vocab_size, embedding_dim)\n",
        "    torch_model = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "    torch_model.weight.data = torch.tensor(my_model.E, dtype=torch.float32)\n",
        "    x_np = np.random.randint(0, vocab_size, input_shape).astype(np.int64)\n",
        "    x_torch = torch.tensor(x_np, dtype=torch.long)\n",
        "    my_output = my_model.forward(x_np)\n",
        "    torch_output = torch_model(x_torch).detach().numpy()\n",
        "    assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {my_output.shape}\"\n",
        "    print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_embedding():\n",
        "    test_cases = [\n",
        "        {'vocab_size': 100, 'embedding_dim': 10, 'input_shape': (32, 20)},\n",
        "        {'vocab_size': 50, 'embedding_dim': 5, 'input_shape': (16, 15)},\n",
        "        {'vocab_size': 200, 'embedding_dim': 20, 'input_shape': (10, 30)}\n",
        "    ]\n",
        "\n",
        "    for idx, params in enumerate(test_cases):\n",
        "        compare_embedding_layers(idx, **params)\n",
        "\n",
        "    print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_embedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VoGJMKCf7rq"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9V2Cn38QUh76"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "  def __init__(self, embedding_dim, hidden_dim):\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.W_xh = np.random.rand(hidden_dim, embedding_dim)\n",
        "    self.W_hh = np.random.rand(hidden_dim, hidden_dim)\n",
        "    self.b_xh = np.random.rand(hidden_dim)\n",
        "    self.b_hh = np.random.rand(hidden_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    input:\n",
        "      x: (N, L, embeeding_dim)\n",
        "    outputs:\n",
        "      output: (N, L, hidden_dim)\n",
        "      last_hidden_state: (1, N, hidden_dim)\n",
        "    '''\n",
        "    batch_size, seq_length = x.shape[0], x.shape[1]\n",
        "    h_0 = np.zeros((batch_size, self.hidden_dim))\n",
        "    hidden_states = []\n",
        "    hidden_states.append(h_0)\n",
        "    for i in range(seq_length):\n",
        "        next_h = np.dot(x[:, i, :], self.W_xh.T) + self.b_xh + np.dot(hidden_states[-1], self.W_hh.T) + self.b_hh\n",
        "        next_h = HelperFunction.tanh(next_h) # (N, hidden_dim)\n",
        "        hidden_states.append(next_h)\n",
        "\n",
        "    output = np.stack(hidden_states[1:], axis=1)\n",
        "    last_hidden_state = hidden_states[-1]\n",
        "\n",
        "    return output, last_hidden_state[np.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3cxXXED3Uun",
        "outputId": "c84d9d21-61b2-43ce-890d-d11e793dcd11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_rnn_layers(idx, embedding_dim, hidden_dim, input_shape):\n",
        "    my_model = RNN(embedding_dim=embedding_dim, hidden_dim=hidden_dim)\n",
        "    torch_model = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "\n",
        "    x_np = np.random.randn(*input_shape).astype(np.float32)\n",
        "    x_torch = torch.tensor(x_np, dtype=torch.float32)\n",
        "\n",
        "    my_output, my_last_hidden_state = my_model.forward(x_np)\n",
        "    torch_output, torch_last_hidden_state = torch_model(x_torch)\n",
        "\n",
        "    torch_output = torch_output.detach().numpy()\n",
        "    torch_last_hidden_state = torch_last_hidden_state.detach().numpy()\n",
        "\n",
        "    assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {my_output.shape}\"\n",
        "    assert torch_last_hidden_state.shape == my_last_hidden_state.shape, f\"Last hidden state shapes do not match: {torch_last_hidden_state.shape} vs {my_last_hidden_state.shape}\"\n",
        "    print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_rnn():\n",
        "    test_cases = [\n",
        "        {'embedding_dim': 10, 'hidden_dim': 20, 'input_shape': (32, 5, 10)},\n",
        "        {'embedding_dim': 15, 'hidden_dim': 25, 'input_shape': (16, 10, 15)},\n",
        "        {'embedding_dim': 8, 'hidden_dim': 16, 'input_shape': (64, 7, 8)}\n",
        "    ]\n",
        "\n",
        "    for idx, params in enumerate(test_cases):\n",
        "        compare_rnn_layers(idx, **params)\n",
        "\n",
        "    print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "# Run the tests\n",
        "check_rnn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuW7JwHKf804"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SYSIMPcbf9bN"
      },
      "outputs": [],
      "source": [
        "class LSTM:\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.W_ii = np.random.rand(hidden_size, input_size)\n",
        "    self.W_hi = np.random.rand(hidden_size, hidden_size)\n",
        "    self.W_if = np.random.rand(hidden_size, input_size)\n",
        "    self.W_hf = np.random.rand(hidden_size, hidden_size)\n",
        "    self.W_ig = np.random.rand(hidden_size, input_size)\n",
        "    self.W_hg = np.random.rand(hidden_size, hidden_size)\n",
        "    self.W_io = np.random.rand(hidden_size, input_size)\n",
        "    self.W_ho = np.random.rand(hidden_size, hidden_size)\n",
        "\n",
        "    self.b_ii = np.random.rand(hidden_size)\n",
        "    self.b_hi = np.random.rand(hidden_size)\n",
        "    self.b_if = np.random.rand(hidden_size)\n",
        "    self.b_hf = np.random.rand(hidden_size)\n",
        "    self.b_ig = np.random.rand(hidden_size)\n",
        "    self.b_hg = np.random.rand(hidden_size)\n",
        "    self.b_io = np.random.rand(hidden_size)\n",
        "    self.b_ho = np.random.rand(hidden_size)\n",
        "\n",
        "  def one_cell(self, x_t, c_prev, h_prev):\n",
        "    '''\n",
        "    Inputs:\n",
        "      x_t: (N, 1, input_size)\n",
        "      c_prev: (N, hidden_size)\n",
        "      h_prev: (N, hidden_size)\n",
        "\n",
        "    Outputs:\n",
        "      c_t: current cell state, (N, hidden_dize)\n",
        "      h_t: current hidden state, (N, hidden_size)\n",
        "\n",
        "    '''\n",
        "    i_t = HelperFunction.sigmoid(np.dot(x_t, self.W_ii.T) + self.b_ii + np.dot(h_prev, self.W_hi.T) + self.b_hi) # (N, hidden_size)\n",
        "    f_t = HelperFunction.sigmoid(np.dot(x_t, self.W_if.T) + self.b_if + np.dot(h_prev, self.W_hf.T) + self.b_hf) # (N, hidden_size)\n",
        "    g_t = HelperFunction.sigmoid(np.dot(x_t, self.W_ig.T) + self.b_ig + np.dot(h_prev, self.W_hg.T) + self.b_hg) # (N, hidden_size)\n",
        "    o_t = HelperFunction.sigmoid(np.dot(x_t, self.W_io.T) + self.b_io + np.dot(h_prev, self.W_ho.T) + self.b_ho) # (N, hidden_size)\n",
        "\n",
        "    c_t = np.multiply(f_t, c_prev) + np.multiply(i_t, g_t)\n",
        "    h_t = np.multiply(o_t, np.tanh(c_t))\n",
        "\n",
        "    return c_t, h_t\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Input:\n",
        "      x: (N, L, input_size)\n",
        "\n",
        "    Outputs:\n",
        "      output: (N, L, hidden_size)\n",
        "      last_hidden_state: (1, N, hidden_size)\n",
        "      last_cell_state: (1, N, hidden_size)\n",
        "    '''\n",
        "    batch_size, seq_length = x.shape[0], x.shape[1]\n",
        "\n",
        "    h_0 = np.zeros((batch_size, self.hidden_size))\n",
        "    c_0 = np.zeros((batch_size, self.hidden_size))\n",
        "    h_records = []\n",
        "    c_records = []\n",
        "\n",
        "    h_records.append(h_0)\n",
        "    c_records.append(c_0)\n",
        "    for i in range(seq_length):\n",
        "      x_t = x[:, i, :]\n",
        "      c_t, h_t = self.one_cell(x_t, c_records[-1], h_records[-1])\n",
        "      h_records.append(h_t)\n",
        "      c_records.append(c_t)\n",
        "\n",
        "    output = np.stack(h_records[1:], axis=1)\n",
        "\n",
        "    last_hidden_state =  h_records[-1]\n",
        "    last_cell_state = c_records[-1]\n",
        "\n",
        "\n",
        "    return output, last_hidden_state[np.newaxis, :], last_cell_state[np.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdbxSwAIrz6M",
        "outputId": "9292d806-e2f9-4004-b2e4-9c6542171ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_lstm_layers(idx, embedding_dim, hidden_dim, input_shape):\n",
        "    my_model = LSTM(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "    torch_model = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "    x_np = np.random.randn(*input_shape).astype(np.float32)\n",
        "    x_torch = torch.tensor(x_np, dtype=torch.float32)\n",
        "\n",
        "    my_output, my_last_hidden_state, my_last_cell_state = my_model.forward(x_np)\n",
        "    torch_output, (torch_last_hidden_state, torch_last_cell_state) = torch_model(x_torch)\n",
        "\n",
        "    torch_output = torch_output.detach().numpy()\n",
        "    torch_last_hidden_state = torch_last_hidden_state.detach().numpy()\n",
        "    torch_last_cell_state = torch_last_cell_state.detach().numpy()\n",
        "\n",
        "    assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {my_output.shape}\"\n",
        "    assert torch_last_hidden_state.shape == my_last_hidden_state.shape, f\"Last hidden state shapes do not match: {torch_last_hidden_state.shape} vs {my_last_hidden_state.shape}\"\n",
        "    assert torch_last_cell_state.shape == my_last_cell_state.shape, f\"Last cekk state shapes do not match: {torch_last_cell_state.shape} vs {my_last_cell_state.shape}\"\n",
        "    print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_lstm():\n",
        "    test_cases = [\n",
        "        {'embedding_dim': 10, 'hidden_dim': 20, 'input_shape': (32, 5, 10)},\n",
        "        {'embedding_dim': 15, 'hidden_dim': 25, 'input_shape': (16, 10, 15)},\n",
        "        {'embedding_dim': 8, 'hidden_dim': 16, 'input_shape': (64, 7, 8)}\n",
        "    ]\n",
        "\n",
        "    for idx, params in enumerate(test_cases):\n",
        "        compare_lstm_layers(idx, **params)\n",
        "\n",
        "    print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_lstm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeSVTVvcm1KK"
      },
      "source": [
        "### MultiHeadAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OwBpZfpcm3Vu"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention:\n",
        "  def __init__(self, embedding_dim, num_heads, source_length, target_length):\n",
        "    self.d_k = embedding_dim // num_heads\n",
        "    self.d_v = embedding_dim // num_heads\n",
        "    self.num_heads = num_heads\n",
        "    self.source_length = source_length\n",
        "    self.target_length = target_length\n",
        "\n",
        "    self.casual_attn_mask = self.create_attn_mask()\n",
        "\n",
        "    self.W_Qs = [np.random.rand(embedding_dim, self.d_k) for _ in range(num_heads)]\n",
        "    self.W_Ks = [np.random.rand(embedding_dim, self.d_k) for _ in range(num_heads)]\n",
        "    self.W_Vs = [np.random.rand(embedding_dim, self.d_v) for _ in range(num_heads)]\n",
        "    self.W_O = np.random.rand(num_heads*self.d_v, embedding_dim)\n",
        "\n",
        "\n",
        "  def create_attn_mask(self):\n",
        "    ''' Create a casual attention mask for LookAhead MultiHeadAttenion Block in Decoder\n",
        "    Shape of attn mask is (target_length, source_length)\n",
        "    '''\n",
        "    if self.target_length != 0:\n",
        "      base = np.zeros((self.target_length, self.source_length))\n",
        "    else:\n",
        "      base = np.zeros((self.source_length, self.source_length))\n",
        "    row, col = base.shape[0], base.shape[1]\n",
        "\n",
        "    for r in range(row-1):\n",
        "      for c in range(col):\n",
        "        if c > r:\n",
        "          base[r, c] = np.NINF\n",
        "    return base # (target_length, source_length)\n",
        "\n",
        "  def softmax(self, x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "  def forward(self, Q, K, V, casual=False):\n",
        "    '''\n",
        "    Q: (N, source_length, embedding_dim)\n",
        "    K: (N, target_length, embedding_dim)\n",
        "    V: (N, target_length, embedding_dim)\n",
        "    '''\n",
        "    attentions = []\n",
        "    for i in range(self.num_heads):\n",
        "      QW = np.dot(Q, self.W_Qs[i]) # (N, target_length, d_k)\n",
        "      KW = np.dot(K, self.W_Ks[i]) # (N, source_length, d_k)\n",
        "      VW = np.dot(V, self.W_Vs[i]) # (N, source_length, d_v)\n",
        "\n",
        "      curr_attention = np.matmul(QW, KW.transpose(0, 2, 1)) / np.sqrt(self.d_k) # (N, target_length, source_length)\n",
        "\n",
        "      if casual:\n",
        "        curr_attention += self.casual_attn_mask # (N, target_length, source_length)\n",
        "\n",
        "      curr_attention = self.softmax(curr_attention) # (N, target_length, source_length)\n",
        "      curr_attention = np.matmul(curr_attention, VW) # (N, target_length, source_length)@(N, source_length, d_v) => (N, target_length, d_v)\n",
        "      attentions.append(curr_attention)\n",
        "\n",
        "    attentions = np.concatenate(attentions, axis=-1)\n",
        "    result = np.dot(attentions, self.W_O) # (N, target_length, num_heads*d_v) @ (num_heads*d_v, embedding_dim) => (N, target_length, embedding_dim)\n",
        "    return result #(N, target_length, embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-4enes3v0Zf",
        "outputId": "6b714b71-4a5a-4de1-c856-f3709b3e9850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mTest 1 passed.\n",
            "\u001b[32mTest 2 passed.\n",
            "\u001b[32mTest 3 passed.\n",
            "\u001b[32mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "def compare_multihead_attention(idx, embedding_dim, num_heads, source_length, target_length, batch_size):\n",
        "    my_model = MultiHeadAttention(embedding_dim=embedding_dim, num_heads=num_heads, source_length=source_length, target_length=target_length)\n",
        "    torch_model = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True)\n",
        "    Q_np = np.random.randn(batch_size, source_length, embedding_dim).astype(np.float32)\n",
        "    K_np = np.random.randn(batch_size, target_length, embedding_dim).astype(np.float32)\n",
        "    V_np = np.random.randn(batch_size, target_length, embedding_dim).astype(np.float32)\n",
        "    Q_torch = torch.tensor(Q_np)\n",
        "    K_torch = torch.tensor(K_np)\n",
        "    V_torch = torch.tensor(V_np)\n",
        "    my_output = my_model.forward(Q_np, K_np, V_np)\n",
        "    torch_output, _ = torch_model(Q_torch, K_torch, V_torch)\n",
        "    torch_output = torch_output.detach().numpy()\n",
        "    assert torch_output.shape == my_output.shape, f\"Shapes do not match: {torch_output.shape} vs {my_output.shape}\"\n",
        "    print(Fore.GREEN + f\"Test {idx+1} passed.\")\n",
        "\n",
        "def check_multihead_attention():\n",
        "    test_cases = [\n",
        "        {'embedding_dim': 16, 'num_heads': 4, 'source_length': 10, 'target_length': 10, 'batch_size': 32},\n",
        "        {'embedding_dim': 32, 'num_heads': 8, 'source_length': 20, 'target_length': 15, 'batch_size': 16},\n",
        "        {'embedding_dim': 64, 'num_heads': 8, 'source_length': 25, 'target_length': 25, 'batch_size': 64}\n",
        "    ]\n",
        "\n",
        "    for idx, params in enumerate(test_cases):\n",
        "      compare_multihead_attention(idx, **params)\n",
        "\n",
        "    print(Fore.GREEN + \"All tests passed!\")\n",
        "\n",
        "check_multihead_attention()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gOVvU6uVKwIP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NKSPldjHBsUk",
        "tnBHIzmyU7Nb",
        "8BV6ZFnOmeNv",
        "oPdknI2Tf6nf",
        "7VoGJMKCf7rq",
        "RuW7JwHKf804",
        "JeSVTVvcm1KK"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
